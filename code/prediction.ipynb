{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:25.455127Z",
     "start_time": "2023-06-05T10:17:25.432969Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import create_VST_model\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "from keras.mixed_precision import policy\n",
    "from keras.utils import tf_inspect\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Use for texture data preprocessing\n",
    "pattern = \"[A-Z]\"\n",
    "pattern1 = '[\"\\\\[\\\\]\\\\\\\\]'\n",
    "pattern2 = \"[*.+!$#&,;{}()':=/<>%-]\"\n",
    "pattern3 = '[_]'\n",
    "\n",
    "# Define basic parameters\n",
    "max_len = 100\n",
    "training_samples = 147\n",
    "validation_samples = 63\n",
    "max_words = 1000\n",
    "\n",
    "# store all data\n",
    "data_set = {}\n",
    "\n",
    "# store file name\n",
    "file_name = []\n",
    "\n",
    "# store structure information\n",
    "data_structure = {}\n",
    "\n",
    "# store texture information\n",
    "data_texture = {}\n",
    "\n",
    "# store token, position and segment information\n",
    "data_token = {}\n",
    "data_position = {}\n",
    "data_segment = {}\n",
    "# dic_content = {}\n",
    "\n",
    "# store the content of each text\n",
    "string_content = {}\n",
    "\n",
    "# store picture information\n",
    "data_picture = {}\n",
    "\n",
    "# store content of each picture\n",
    "data_image = []\n",
    "\n",
    "# experimental part â€” randomly shuffling data\n",
    "all_data = []\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "structure = []\n",
    "image = []\n",
    "token = []\n",
    "segment = []\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:25.457047Z",
     "start_time": "2023-06-05T10:17:25.436441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load the BertTokenizer\n"
     ]
    }
   ],
   "source": [
    "# Define the basic bert class\n",
    "class BertConfig(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = kwargs.pop('vocab_size', 30000)\n",
    "        self.type_vocab_size = kwargs.pop('type_vocab_size', 300)\n",
    "        self.hidden_size = kwargs.pop('hidden_size', 768)\n",
    "        self.num_hidden_layers = kwargs.pop('num_hidden_layers', 12)\n",
    "        self.num_attention_heads = kwargs.pop('num_attention_heads', 12)\n",
    "        self.intermediate_size = kwargs.pop('intermediate_size', 3072)\n",
    "        self.hidden_activation = kwargs.pop('hidden_activation', 'gelu')\n",
    "        self.hidden_dropout_rate = kwargs.pop('hidden_dropout_rate', 0.1)\n",
    "        self.attention_dropout_rate = kwargs.pop('attention_dropout_rate', 0.1)\n",
    "        self.max_position_embeddings = kwargs.pop('max_position_embeddings', 200)\n",
    "        self.max_sequence_length = kwargs.pop('max_sequence_length', 200)\n",
    "\n",
    "\n",
    "class BertEmbedding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(name='BertEmbedding')\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.token_embedding = self.add_weight('weight', shape=[self.vocab_size, self.hidden_size],\n",
    "                                               initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))\n",
    "        self.type_vocab_size = config.type_vocab_size\n",
    "\n",
    "        self.position_embedding = tf.keras.layers.Embedding(\n",
    "            config.max_position_embeddings,\n",
    "            config.hidden_size,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "            name='position_embedding'\n",
    "        )\n",
    "        self.token_type_embedding = tf.keras.layers.Embedding(\n",
    "            config.type_vocab_size,\n",
    "            config.hidden_size,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "            name='token_type_embedding'\n",
    "        )\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-12, name='LayerNorm')\n",
    "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        with tf.name_scope('bert_embeddings'):\n",
    "            super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False, mode='embedding'):\n",
    "        # used for masked lm\n",
    "        if mode == 'linear':\n",
    "            return tf.matmul(inputs, self.token_embedding, transpose_b=True)\n",
    "\n",
    "        input_ids, token_type_ids = inputs\n",
    "        input_ids = tf.cast(input_ids, dtype=tf.int32)\n",
    "        position_ids = tf.range(input_ids.shape[1], dtype=tf.int32)[tf.newaxis, :]\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = tf.fill(input_ids.shape.as_list(), 0)\n",
    "\n",
    "        position_embeddings = self.position_embedding(position_ids)\n",
    "        token_type_embeddings = self.token_type_embedding(token_type_ids)\n",
    "        token_embeddings = tf.gather(self.token_embedding, input_ids)\n",
    "\n",
    "        embeddings = token_embeddings + token_type_embeddings + position_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings, training=training)\n",
    "        return embeddings\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Returns the config of the layer.\n",
    "\n",
    "        A layer config is a Python dictionary (serializable)\n",
    "        containing the configuration of a layer.\n",
    "        The same layer can be reinstantiated later\n",
    "        (without its trained weights) from this configuration.\n",
    "\n",
    "        The config of a layer does not include connectivity\n",
    "        information, nor the layer class name. These are handled\n",
    "        by `Network` (one layer of abstraction above).\n",
    "\n",
    "        Returns:\n",
    "            Python dictionary.\n",
    "        \"\"\"\n",
    "        all_args = tf_inspect.getfullargspec(self.__init__).args\n",
    "        config = {\n",
    "            'name': self.name,\n",
    "            'trainable': self.trainable,\n",
    "        }\n",
    "        if hasattr(self, '_batch_input_shape'):\n",
    "            config['batch_input_shape'] = self._batch_input_shape\n",
    "        config['dtype'] = policy.serialize(self._dtype_policy)\n",
    "        if hasattr(self, 'dynamic'):\n",
    "            # Only include `dynamic` in the `config` if it is `True`\n",
    "            if self.dynamic:\n",
    "                config['dynamic'] = self.dynamic\n",
    "            elif 'dynamic' in all_args:\n",
    "                all_args.remove('dynamic')\n",
    "        expected_args = config.keys()\n",
    "        # Finds all arguments in the `__init__` that are not in the config:\n",
    "        extra_args = [arg for arg in all_args if arg not in expected_args]\n",
    "        # Check that either the only argument in the `__init__` is  `self`,\n",
    "        # or that `get_config` has been overridden:\n",
    "        if len(extra_args) > 1 and hasattr(self.get_config, '_is_default'):\n",
    "            raise NotImplementedError('Layer %s has arguments in `__init__` and '\n",
    "                                      'therefore must override `get_config`.' %\n",
    "                                      self.__class__.__name__)\n",
    "        return config\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('google/bert_uncased_L-12_H-768_A-12')\n",
    "print('Successfully load the BertTokenizer')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:25.744075Z",
     "start_time": "2023-06-05T10:17:25.439178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = create_VST_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.005045Z",
     "start_time": "2023-06-05T10:17:25.749617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model.load_weights('/Users/agnia.sergeyuk/PycharmProjects/Readability-Features/Experimental output/VST_BEST.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.049997Z",
     "start_time": "2023-06-05T10:17:26.005471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "structure_dir = '/Users/agnia.sergeyuk/PycharmProjects/Readability-Features/code/OUR_Dataset/Processed Dataset/Structure'\n",
    "texture_dir = '/Users/agnia.sergeyuk/PycharmProjects/Readability-Features/code/OUR_Dataset/Processed Dataset/Texture'\n",
    "picture_dir = '/Users/agnia.sergeyuk/PycharmProjects/Readability-Features/code/OUR_Dataset/Processed Dataset/Image'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.052366Z",
     "start_time": "2023-06-05T10:17:26.050437Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def preprocess_new_structure_data(structure_dir):\n",
    "    for f_name in os.listdir(structure_dir):\n",
    "        f = open(os.path.join(structure_dir, f_name), errors='ignore')\n",
    "        lines = []\n",
    "        \n",
    "        if not f_name.startswith('.'):\n",
    "            file_name.append(f_name.split('.')[0])\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip(' \\n')\n",
    "                info = line.split(' ')\n",
    "                info_int = []\n",
    "                \n",
    "                count = 0\n",
    "                max_elements = 305\n",
    "                \n",
    "                for item in info:\n",
    "                    if count < max_elements:\n",
    "                        info_int.append(int(item))\n",
    "                        count += 1  \n",
    "\n",
    "                info_int = np.asarray(info_int)\n",
    "                lines.append(info_int)\n",
    "            f.close()\n",
    "            \n",
    "            lines = np.asarray(lines)\n",
    "            data_structure[f_name.split('.')[0]] = lines\n",
    "    return data_structure"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.056083Z",
     "start_time": "2023-06-05T10:17:26.054271Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def preprocess_new_texture_data(texture_dir):\n",
    "    for f_name in os.listdir(texture_dir):\n",
    "        if f_name[-4:] == \".txt\":\n",
    "            list_content = []\n",
    "            list_position = []\n",
    "            list_segment = []\n",
    "            s = ''\n",
    "            segment_id = 0\n",
    "            position_id = 0\n",
    "            count = 0\n",
    "            f = open(os.path.join(texture_dir, f_name), errors='ignore')\n",
    "            for content in f:\n",
    "                content = re.sub(r\"([a-z]+)([A-Z]+)\", r\"\\1 \\2\", content)\n",
    "                content = re.sub(pattern1, lambda x: \" \" + x.group(0) + \" \", content)\n",
    "                content = re.sub(pattern2, lambda x: \" \" + x.group(0) + \" \", content)\n",
    "                content = re.sub(pattern3, lambda x: \" \", content)\n",
    "                list_value = content.split()\n",
    "                for item in list_value:\n",
    "                    if len(item) > 1 or not item.isalpha():\n",
    "                        s = s + ' ' + item\n",
    "                        list_content.append(item)\n",
    "                        if count < max_len:\n",
    "                            list_position.append(position_id)\n",
    "                            position_id += 1\n",
    "                            list_segment.append(segment_id)\n",
    "                        count += 1\n",
    "                segment_id += 1\n",
    "            while count < max_len:\n",
    "                list_segment.append(segment_id)\n",
    "                list_position.append(count)\n",
    "                count += 1\n",
    "            f.close()\n",
    "            string_content[f_name.split('.')[0]] = s\n",
    "            data_position[f_name.split('.')[0]] = list_position\n",
    "            data_segment[f_name.split('.')[0]] = list_segment\n",
    "\n",
    "    for sample in string_content:\n",
    "        list_token = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(string_content[sample]))\n",
    "        list_token = list_token[:max_len]\n",
    "        while len(list_token) < max_len:\n",
    "            list_token.append(0)\n",
    "        data_token[sample] = list_token\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.061303Z",
     "start_time": "2023-06-05T10:17:26.059708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def preprocess_new_picture_data(picture_dir):\n",
    "    for f_name in os.listdir(picture_dir):\n",
    "        if not f_name.startswith('.') and f_name[-4:] in ['.jpg', '.jpeg', '.png']:\n",
    "            img_data = cv2.imread(os.path.join(picture_dir, f_name))\n",
    "            img_data = cv2.resize(img_data, (128, 128))\n",
    "            result = img_data / 255.0\n",
    "            data_picture[f_name.split('.')[0]] = result\n",
    "            data_image.append(result)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.064437Z",
     "start_time": "2023-06-05T10:17:26.062659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def prepare_data_for_prediction():\n",
    "    count_id = 0\n",
    "    while count_id < 69 and count_id < len(file_name):\n",
    "        all_data.append(file_name[count_id])\n",
    "        count_id += 1\n",
    "    for item in all_data:\n",
    "        structure.append(data_structure[item])\n",
    "        image.append(data_picture[item])\n",
    "        token.append(data_token[item])\n",
    "        segment.append(data_segment[item])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.068528Z",
     "start_time": "2023-06-05T10:17:26.066814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "preprocess_new_structure_data(structure_dir)\n",
    "preprocess_new_texture_data(texture_dir)\n",
    "preprocess_new_picture_data(picture_dir)\n",
    "prepare_data_for_prediction()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.457627Z",
     "start_time": "2023-06-05T10:17:26.068762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# format the data\n",
    "structure = np.asarray(structure,  dtype=np.float32)\n",
    "image = np.asarray(image,  dtype=np.float32)\n",
    "token = np.asarray(token,  dtype=np.float32)\n",
    "segment = np.asarray(segment,  dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:26.462400Z",
     "start_time": "2023-06-05T10:17:26.458365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 12:17:26.496572: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 101ms/step\n"
     ]
    }
   ],
   "source": [
    "data_to_predict = [structure, token, segment, image]\n",
    "result = model.predict(data_to_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:27.048378Z",
     "start_time": "2023-06-05T10:17:26.466393Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "file_names_column = []\n",
    "predictions_column = []\n",
    "\n",
    "for i, pred in enumerate(result):\n",
    "    file_names_column.append(all_data[i])\n",
    "    predictions_column.append(pred)\n",
    "\n",
    "data = {\n",
    "    'file_Name': file_names_column,\n",
    "    'readability_score': predictions_column\n",
    "}\n",
    "\n",
    "prediction_df = pd.DataFrame(data)\n",
    "prediction_df['readability_score'] = prediction_df['readability_score'].astype(float)\n",
    "prediction_df['readability'] = round(prediction_df['readability_score'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:27.052342Z",
     "start_time": "2023-06-05T10:17:27.050417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   file_Name  readability_score  readability\n0         27           0.008861          0.0\n1          1           0.006001          0.0\n2         15           0.996771          1.0\n3          8           0.044021          0.0\n4         32           0.000000          0.0\n5         42           0.036882          0.0\n6         19           0.996055          1.0\n7         47           0.117769          0.0\n8         37           0.129220          0.0\n9          4           0.075198          0.0\n10        22           0.057660          0.0\n11        10           0.039320          0.0\n12        13           0.063569          0.0\n13        21           0.999999          1.0\n14         7           0.658174          1.0\n15        44           0.999904          1.0\n16        34           0.026074          0.0\n17        28           0.351424          0.0\n18        31           0.892784          1.0\n19        41           0.005622          0.0\n20        16           0.000000          0.0\n21        48           0.035735          0.0\n22        38           0.354387          0.0\n23         2           0.075963          0.0\n24        24           0.111198          0.0\n25        11           0.065749          0.0\n26        23           0.994486          1.0\n27         5           0.171510          0.0\n28        18           0.045982          0.0\n29        36           0.976077          1.0\n30        46           0.006682          0.0\n31        43           0.997912          1.0\n32        33           0.098415          0.0\n33         9           0.022807          0.0\n34        14           0.380284          0.0\n35        26           0.002050          0.0\n36        25           0.989690          1.0\n37         3           0.013326          0.0\n38        17           0.009674          0.0\n39        39           0.903149          1.0\n40        49           0.648810          1.0\n41        40           0.242172          0.0\n42        30           0.080266          0.0\n43        29           0.903307          1.0\n44        35           0.977237          1.0\n45        45           0.166484          0.0\n46         6           0.373231          0.0\n47        20           0.001730          0.0\n48        12           0.156295          0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_Name</th>\n      <th>readability_score</th>\n      <th>readability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>27</td>\n      <td>0.008861</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.006001</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>0.996771</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>0.044021</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>42</td>\n      <td>0.036882</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>19</td>\n      <td>0.996055</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47</td>\n      <td>0.117769</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>37</td>\n      <td>0.129220</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>0.075198</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22</td>\n      <td>0.057660</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>0.039320</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.063569</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>21</td>\n      <td>0.999999</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7</td>\n      <td>0.658174</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>44</td>\n      <td>0.999904</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>34</td>\n      <td>0.026074</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>28</td>\n      <td>0.351424</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>31</td>\n      <td>0.892784</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>41</td>\n      <td>0.005622</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>48</td>\n      <td>0.035735</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>38</td>\n      <td>0.354387</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2</td>\n      <td>0.075963</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0.111198</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>11</td>\n      <td>0.065749</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>23</td>\n      <td>0.994486</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>5</td>\n      <td>0.171510</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>18</td>\n      <td>0.045982</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>36</td>\n      <td>0.976077</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>46</td>\n      <td>0.006682</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>43</td>\n      <td>0.997912</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>0.098415</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>9</td>\n      <td>0.022807</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>14</td>\n      <td>0.380284</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>26</td>\n      <td>0.002050</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>25</td>\n      <td>0.989690</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>3</td>\n      <td>0.013326</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>17</td>\n      <td>0.009674</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>0.903149</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>49</td>\n      <td>0.648810</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>40</td>\n      <td>0.242172</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>30</td>\n      <td>0.080266</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>29</td>\n      <td>0.903307</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>35</td>\n      <td>0.977237</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>0.166484</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>6</td>\n      <td>0.373231</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>20</td>\n      <td>0.001730</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>12</td>\n      <td>0.156295</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:27.065451Z",
     "start_time": "2023-06-05T10:17:27.053947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:27.065867Z",
     "start_time": "2023-06-05T10:17:27.061578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T10:17:27.065945Z",
     "start_time": "2023-06-05T10:17:27.063888Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
